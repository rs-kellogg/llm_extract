{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ddecdc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Run on KLC\n",
    "\n",
    "#### *<span style=\"color:purple\"><em>Run LLMs on KLC</em></span>*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aee599e",
   "metadata": {},
   "source": [
    "#### Create Env\n",
    ":::{admonition} Create a conda environment\n",
    "\n",
    "Start from a clean slate\n",
    "\n",
    "```module purge```\n",
    "\n",
    "Load the mamba module \n",
    "\n",
    "```module load mamba```\n",
    "\n",
    "Create the environment in a specified path\n",
    "\n",
    "```mamba create -p /home/<net_id>/extract_llm python=3.11 google-generativeai openai -y ```\n",
    "\n",
    "Activate the environment\n",
    "\n",
    "```source activate /home/<net_id>/extract_llm ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59a7982",
   "metadata": {},
   "source": [
    "#### Use Shared Env\n",
    ":::{admonition} Using our shared environment\n",
    "\n",
    "\n",
    "Start from a clean slate\n",
    "\n",
    "```module purge```\n",
    "\n",
    "Load the mamba module \n",
    "\n",
    "```module load mamba```\n",
    "\n",
    "Activate the environment\n",
    "\n",
    "```source activate /kellogg/software/envs/extract_llm25_env```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5635ab4c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Get Files\n",
    ":::{admonition} Obtain Files\n",
    "\n",
    "Clone the git repo\n",
    "\n",
    "```git clone https://github.com/rs-kellogg/2025_phd_workshop```\n",
    "\n",
    "Navigate to directory \n",
    "\n",
    "```cd llm_extract/lab1/```\n",
    "\n",
    "Activate git to track changes\n",
    "\n",
    "```git init```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6fe8d1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Modify and Run \n",
    ":::{admonition} Modify and Run Code\n",
    "\n",
    "Modify the file (Note that control + x saves changes in the nano editor)\n",
    "\n",
    "```nano gemini_call.py```\n",
    "\n",
    "Run the file\n",
    "\n",
    "```python gemini_call.py```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6856f05",
   "metadata": {},
   "source": [
    "#### Version Control\n",
    ":::{admonition} Save changes with git\n",
    "\n",
    "Save file changes in your working directory to the staging area\n",
    "\n",
    "```git add gemini_call.py```\n",
    "\n",
    "\n",
    "Move changes from the staging area to your Git history\n",
    "\n",
    "```git commit -m \"add prompt text file```\n",
    "\n",
    "Check if any file changes still need to be saved\n",
    "\n",
    "```git status```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca036687",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "source": [
    "#### Lab 1\n",
    ":::{admonition} Lab 1 - Run your first API Call!\n",
    "\n",
    "The sample code to use can be found here:\n",
    "[GPT example](../code/lab1/gpt_call.py)\n",
    "[Gemini example](../code/lab1/gemini_call.py)\n",
    "\n",
    "Use either the python script for Gemini or GPT (depennding on your API token).\n",
    "\n",
    "1. Use the nano editor to change your prompt.\n",
    "\n",
    "2. Run the code and let us know when you obtain an LLM response!\n",
    "\n",
    "3. Save your changes to git.\n",
    "\n",
    "4. CHALLENGE - Can you write a prompt to get your LLM to hallucinate (provide misinformation)?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}